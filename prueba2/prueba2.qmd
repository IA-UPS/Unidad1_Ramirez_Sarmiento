---
title: "Tarea"
author: "Ramirez Juan, Sarmiento Nimrod"
format: html
editor: visual
---

# Métodos de clasificación

#### Cargamos librerías

```{r warning=FALSE}
library(ggplot2)
library(ggpubr)
library(dplyr)
library(glmnet) ## regresiones logisitcas
library(caret) ### bayes y knn
library(e1071) ## bayes
library(naivebayes) ##bayes
```

#### Cargamos datos

```{r warning=FALSE}
datos <- read.table("./yeast.data",header = F)[,-1]
```

Crear funciones para la normalizacion

```{r warning=FALSE}
min.max.mean <- function(X) apply(X,2,function(x) (x-mean(x))/(max(x)-min(x)))
min.max.median <- function(X) apply(X,2,function(x) (x-median(x))/(max(x)-min(x)))
min.max <- function(X) apply(X,2,function(x) (x-min(x))/(max(x)-min(x)))
zscore <- function(X) apply(X,2,function(x) (x-mean(x))/sd(x))
l2 <- function(X) apply(X,2,function(x) x/sqrt(sum(x^2)))  
```

Se necesita datos numericos

```{r warning=FALSE}
datos <- as.data.frame(datos)
datos.numericos <- datos[, which(unlist(lapply(datos, is.numeric)))]
clase <- datos$V10 <- as.factor(datos$V10)
colnames(datos.numericos) <- paste0("Var", rep(1:8))

```

Se crea una lista de todas las transformaciones

```{r warning=FALSE}
datos.lista <- list(
  raw = bind_cols(datos.numericos,clase=clase),
  zscore = bind_cols(zscore(datos.numericos),
                     clase = clase),
  l2 = bind_cols(l2(datos.numericos), clase = clase),
  media = bind_cols(min.max.mean(datos.numericos), clase =
                      clase),
  mediana = bind_cols(min.max.median(datos.numericos), clase =
                        clase),
  min_max = bind_cols(min.max(datos.numericos),
  clase = clase))
```

Partición de los datos

```{r warning=FALSE}
set.seed(123456789)
n  <- nrow(datos)
idx <- sample(1:n,n*0.7)
### para conjunto de datos podemos realizar el split
datos.train.lista <- lapply(datos.lista, function(x) x[idx,])
datos.test.lista <- lapply(datos.lista, function(x) x[-idx,])
```

#### Regresión Lineal

```{r warning=FALSE}
set.seed(5768)

tC <- trainControl(method = 'cv',
                          number = 5)
log <- function(x) train(clase ~ ., data = x, method = "multinom", tC = tC, trace = F)

logist.lista <- lapply(datos.train.lista,log)


logist.pred <- vector("list",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  logist.pred[[l]] <- predict(logist.lista[[l]],datos.test.lista[[l]])
  
  
}

names(logist.pred) <- names(datos.lista)
accuracy <- vector("numeric",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  accuracy[l] <- confusionMatrix(datos.test.lista$raw$clase,logist.pred[[l]])$overall[1]
  
  
}

names(accuracy) <- names(datos.lista)

print(accuracy)
```

#### **Método de Lasso**

```{r warning=FALSE}

set.seed(5768)
trControl <- trainControl(method = 'cv',
                          number = 5)
myfnloglasso <- function(x) train(clase ~ ., data = x, method = "glmnet", trControl = trControl, tuneGrid = expand.grid(alpha = 1, lambda = seq(0, 1, by = 0.001)), trace = F)

logistica.lista.lasso <- lapply(datos.train.lista,myfnloglasso)


logisita.pred.lasso <- vector("list",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  logisita.pred.lasso[[l]] <- predict(logistica.lista.lasso[[l]],datos.test.lista[[l]])
  
  
}

names(logisita.pred.lasso) <- names(datos.lista)
accuracy.lasso <- vector("numeric",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  accuracy.lasso[l] <- confusionMatrix(datos.test.lista$raw$clase,logisita.pred.lasso[[l]])$overall[1]
  
  
}

names(accuracy.lasso) <- names(datos.lista)

print(accuracy.lasso)
```

#### Método de Ridge

```{r warning=FALSE}}

set.seed(5768)
trControl <- trainControl(method = 'cv',
                          number = 5)
myfnlogridge <- function(x) train(clase ~ ., data = x, method = "glmnet", trControl = trControl, tuneGrid = expand.grid(alpha = 0, lambda = seq(0, 1, by = 0.001)), trace = F)

logistica.lista.ridge <- lapply(datos.train.lista,myfnlogridge)


logisita.pred.ridge <- vector("list",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  logisita.pred.ridge[[l]] <- predict(logistica.lista.ridge[[l]],datos.test.lista[[l]])
  
  
}

names(logisita.pred.ridge) <- names(datos.lista)
accuracy.ridge <- vector("numeric",length = length(datos.lista))

for(l in 1:length(datos.lista)){
  
  accuracy.ridge[l] <- confusionMatrix(datos.test.lista$raw$clase,logisita.pred.ridge[[l]])$overall[1]
  
  
}

names(accuracy.ridge) <- names(datos.lista)

print(accuracy.ridge)
```

#### Metodo de KNN

```{r warning=FALSE}
set.seed(5768)

k_values = c(1:20)

ctrl <- trainControl(method = "repeatedcv", number =3,
                     repeats = 10)


myfnknn <- function(x) train(clase ~ ., data = x, method = "knn", trControl = ctrl, tuneGrid = data.frame(k=k_values))



knn.lista <- lapply(datos.train.lista, myfnknn)



knn.pred <- vector("list", length = length(datos.lista))


for(l in 1:length(datos.lista)){
 
  knn.pred[[l]] <- predict(knn.lista[[l]], datos.test.lista[[l]])
  
}


names(knn.pred) <- names(datos.lista)


accuracy.knn <- vector("numeric", length = length(datos.lista))


for(l in 1:length(datos.lista)){
  accuracy.knn[l] <- confusionMatrix(datos.test.lista$raw$clase,knn.pred[[l]])$overall[1]
  }
names(accuracy.knn) <- names(datos.lista)
```

#### Metodo de Bayes

```{r warning=FALSE}
set.seed(5768)


trControl <- trainControl(method = "cv", number = 10)


myfnbayes <- function(x) train(clase ~ ., data = x, method = "naive_bayes", trControl = trControl)



bayes.lista <- lapply(datos.train.lista, myfnbayes)



bayes.pred <- vector("list", length = length(datos.lista))


for(l in 1:length(datos.lista)){
 
  bayes.pred[[l]] <- predict(bayes.lista[[l]], datos.test.lista[[l]])
  
}


names(bayes.pred) <- names(datos.lista)


accuracy.bayes <- vector("numeric", length = length(datos.lista))


for(l in 1:length(datos.lista)){
  accuracy.bayes[l] <- confusionMatrix(datos.test.lista$raw$clase,bayes.pred[[l]])$overall[1]
  }
names(accuracy.bayes) <- names(datos.lista)
```
